{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bb906a-a950-4625-b41f-9ed3d51b218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/01 23:29:16 WARN Utils: Your hostname, zurich-VivoBook-ASUSLaptop-X412FL-A412FL, resolves to a loopback address: 127.0.1.1; using 10.113.113.182 instead (on interface wlo1)\n",
      "25/09/01 23:29:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/01 23:29:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Membuat proyek awal menggunakan PySpark dan Pandas\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Menginisialisasi sesi Spark\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Menyusun DataFrame sederhana dengan data contoh\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan isi DataFrame ke layar\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb9c1f4-c660-45f1-8262-6c73619f685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+---------+------+\n",
      "| Nama|Usia|Pekerjaan|     Hobi|Gender|\n",
      "+-----+----+---------+---------+------+\n",
      "|  Ali|  34|      TNI|Memancing|     L|\n",
      "| Budi|  23|      TNI| Olahraga|     L|\n",
      "|Citra|  29|     Guru|    Senam|     P|\n",
      "| Dina|  45| Karyawan|    Senam|     P|\n",
      "+-----+----+---------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tugas 1: Jalankan program berikut lalu lakukan modifikasi \n",
    "# dengan menambahkan atribut baru seperti pekerjaan, hobi, dan gender\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Mengaktifkan sesi Spark\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Menyusun DataFrame dengan tambahan kolom pekerjaan, hobi, serta gender\n",
    "data = [(\"Ali\", 34, \"TNI\", \"Memancing\", \"L\"),\n",
    "        (\"Budi\", 23, \"TNI\", \"Olahraga\", \"L\"),\n",
    "        (\"Citra\", 29, \"Guru\", \"Senam\", \"P\"),\n",
    "        (\"Dina\", 45, \"Karyawan\", \"Senam\", \"P\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan hasil DataFrame ke output\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e004136-5bdf-4c2b-bb15-e1d74b9220c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---------+---------+------+\n",
      "| Nama|Usia|Pekerjaan|     Hobi|Gender|\n",
      "+-----+----+---------+---------+------+\n",
      "|  Ali|  34|      TNI|Memancing|     L|\n",
      "| Budi|  23|      TNI| Olahraga|     L|\n",
      "|Citra|  29|     Guru|    Senam|     P|\n",
      "| Dina|  45| Karyawan|    Senam|     P|\n",
      "+-----+----+---------+---------+------+\n",
      "\n",
      "+----+----+---------+---------+------+\n",
      "|Nama|Usia|Pekerjaan|     Hobi|Gender|\n",
      "+----+----+---------+---------+------+\n",
      "| Ali|  34|      TNI|Memancing|     L|\n",
      "|Dina|  45| Karyawan|    Senam|     P|\n",
      "+----+----+---------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (2 + 2) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|    32.75|\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Praktik PySpark Tingkat Lanjut\n",
    "# Latihan 1: Manipulasi Data dengan PySpark\n",
    "# Tugas 2: Terapkan filter, hitung nilai rata-rata, dan urutkan data menggunakan PySpark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Membuka sesi kerja Spark\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame dengan beberapa kolom tambahan\n",
    "data = [(\"Ali\", 34, \"TNI\", \"Memancing\", \"L\"),\n",
    "        (\"Budi\", 23, \"TNI\", \"Olahraga\", \"L\"),\n",
    "        (\"Citra\", 29, \"Guru\", \"Senam\", \"P\"),\n",
    "        (\"Dina\", 45, \"Karyawan\", \"Senam\", \"P\")]\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\", \"Hobi\", \"Gender\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan isi DataFrame awal\n",
    "df.show()\n",
    "\n",
    "# Menyaring data (filter) untuk menampilkan usia di atas 30 tahun\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata kolom usia\n",
    "from pyspark.sql.functions import avg\n",
    "df.groupBy().agg(avg(\"Usia\")).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan usia dari yang tertinggi ke terendah\n",
    "df_sorted = df.orderBy(\"Usia\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31864394-81d1-4be5-a8c6-54441be2880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Usia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budi</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citra</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nama  Usia\n",
       "0    Ali    34\n",
       "1   Budi    23\n",
       "2  Citra    29\n",
       "3   Dina    45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Praktik menggunakan Pandas\n",
    "# Latihan 2: Membuat DataFrame dengan library Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Menyusun DataFrame sederhana menggunakan Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menampilkan isi DataFrame yang dibuat dengan Pandas\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7fa883-f3c6-4b96-b425-f64f0f4aa95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Usia</th>\n",
       "      <th>Kategori Usia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>34</td>\n",
       "      <td>Dewasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>45</td>\n",
       "      <td>Dewasa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nama  Usia Kategori Usia\n",
       "0   Ali    34        Dewasa\n",
       "3  Dina    45        Dewasa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tugas 3: Modifikasi DataFrame Pandas dengan menambahkan kolom baru\n",
    "# serta melakukan penyaringan data berdasarkan usia\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame awal menggunakan Pandas\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"],\n",
    "               \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menambahkan kolom tambahan 'Kategori Usia' dengan kondisi tertentu\n",
    "df_pandas[\"Kategori Usia\"] = df_pandas[\"Usia\"].apply(lambda x: \"Muda\" if x < 30 else \"Dewasa\")\n",
    "\n",
    "# Menyaring data: hanya menampilkan baris dengan usia lebih dari 30 tahun\n",
    "df_filtered = df_pandas[df_pandas[\"Usia\"] > 30]\n",
    "\n",
    "# Menampilkan DataFrame hasil modifikasi\n",
    "df_pandas\n",
    "display(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc211a72-8637-4e39-b89a-a2728cde2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nama  Usia Pekerjaan\n",
      "0    Ali    34    Dokter\n",
      "1   Budi    23      Guru\n",
      "2  Citra    29  Insinyur\n",
      "3   Dina    45   Perawat\n",
      "            Usia\n",
      "count   4.000000\n",
      "mean   32.750000\n",
      "std     9.322911\n",
      "min    23.000000\n",
      "25%    27.500000\n",
      "50%    31.500000\n",
      "75%    36.750000\n",
      "max    45.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Praktik Lanjutan dengan Pandas\n",
    "# Latihan 3: Menerapkan operasi yang lebih kompleks menggunakan Pandas\n",
    "# Tugas 4: Lakukan penggabungan antar DataFrame serta tampilkan visualisasi data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame pertama (berisi nama dan usia)\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua (berisi nama dan pekerjaan)\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"],\n",
    "                 \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Menggabungkan kedua DataFrame berdasarkan kolom 'Nama'\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "print(df_joined)\n",
    "\n",
    "# Menampilkan statistik deskriptif dari DataFrame pertama\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Membuat visualisasi sederhana berupa diagram batang untuk kolom 'Usia'\n",
    "import matplotlib.pyplot as plt\n",
    "df_pandas['Usia'].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb8c184-526b-4c8f-8f2a-cc72891b36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Nama  Usia Pekerjaan       Hobi Gender\n",
       " 0    Ali    34       TNI  Memancing      L\n",
       " 1   Budi    23       TNI   Olahraga      L\n",
       " 2  Citra    29      Guru      Senam      P\n",
       " 3   Dina    45  Karyawan      Senam      P,\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengintegrasikan PySpark dengan Pandas\n",
    "# Latihan 4: Mengonversi DataFrame antara PySpark dan Pandas\n",
    "# Contoh praktik konversi DataFrame dari PySpark ke Pandas serta dari Pandas ke PySpark\n",
    "\n",
    "# Konversi DataFrame dari PySpark ke dalam format Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Konversi DataFrame dari Pandas menjadi DataFrame PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan hasil DataFrame yang sudah dikonversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7542bca-3e79-412f-9859-3687a12879e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/01 23:43:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "|  Eka|  31|\n",
      "|Fajar|  27|\n",
      "+-----+----+\n",
      "\n",
      "+--------------+\n",
      "|Rata-rata Usia|\n",
      "+--------------+\n",
      "|          31.5|\n",
      "+--------------+\n",
      "\n",
      "+-------------+\n",
      "|Usia Maksimum|\n",
      "+-------------+\n",
      "|           45|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tugas 5: Manfaatkan metode konversi untuk menggabungkan data dari PySpark dengan data Pandas\n",
    "# Setelah itu lakukan analisis sederhana seperti menghitung rata-rata usia\n",
    "# Tugas 6: Lanjutkan dengan penggabungan data PySpark dan Pandas\n",
    "# Kemudian terapkan operasi statistika, misalnya mencari usia maksimum\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, max\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Membuat atau memulai sesi Spark\n",
    "spark = SparkSession.builder.appName(\"GabungDataPySparkPandas\").getOrCreate()\n",
    "\n",
    "# 2. Dataset awal yang dibuat dengan PySpark\n",
    "data_spark = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "df_spark = spark.createDataFrame(data_spark, columns)\n",
    "\n",
    "# 3. Dataset tambahan yang dibuat menggunakan Pandas\n",
    "data_pandas = {\n",
    "    \"Nama\": [\"Eka\", \"Fajar\"],\n",
    "    \"Usia\": [31, 27]\n",
    "}\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# 4. Ubah DataFrame Pandas menjadi DataFrame PySpark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# 5. Menggabungkan DataFrame PySpark awal dengan hasil konversi dari Pandas\n",
    "df_combined = df_spark.union(df_spark_from_pandas)\n",
    "\n",
    "# 6. Menampilkan DataFrame gabungan\n",
    "df_combined.show()\n",
    "\n",
    "# 7. Analisis sederhana: menghitung nilai rata-rata usia\n",
    "df_combined.groupBy().agg(avg(\"Usia\").alias(\"Rata-rata Usia\")).show()\n",
    "\n",
    "# 8. Analisis tambahan: menghitung nilai maksimum pada kolom Usia\n",
    "df_combined.agg(max(\"Usia\").alias(\"Usia Maksimum\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1ed06-99fe-4cba-aec5-daf4d7408be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
